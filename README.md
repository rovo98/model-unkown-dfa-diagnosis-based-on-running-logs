
## Fault Diagnosis in unknown model DES

### project structures

```text
.
â”œâ”€â”€ data_preprocessing
â”œâ”€â”€ dataset             # Stores processed running logs (compressed)
â”œâ”€â”€ encoding-configs    # stores config for encoding new come running logs
â”œâ”€â”€ images              # images for README.md
â”œâ”€â”€ models              # DL models
â”œâ”€â”€ README.md
â””â”€â”€â”€ requirements.txt

python version : 3.7.4
```

ä½¿ç”¨æ·±åº¦å­¦ä¹ æ–¹æ³•ï¼ŒåŸºäº DES (ç¦»æ•£äº‹ä»¶ç³»ç»Ÿ) ç”Ÿæˆçš„æ—¥å¿— (running logs) æ¥è¿›è¡Œé”™è¯¯è¯Šæ–­ï¼Œæœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªåºåˆ— (sequence) çš„åˆ†ç±» (classification) é—®é¢˜ .

> å³æ‰¾å¯»é€‚åˆè¯¥åå¤åˆ†ç±»é—®é¢˜çš„æœºå™¨å­¦ä¹ æ–¹æ³•ï¼Œå®Œæˆè¯¥ä»»åŠ¡ã€‚é‡ç‚¹çœ‹å¦‚ä½•å€Ÿé‰´å·²æœ‰å¯¹æ–‡æœ¬åºåˆ—è¿›è¡Œåˆ†ç±»çš„ä¾‹å­ï¼ŒCNN (Convolution Neural Network) æˆ– RNN (Recurrent Neural Network) å¯èƒ½å¯è¡Œã€‚


### 1. Main Idea

Using one dimensional convolutional neural networks (CNNs), recurrent neural networks (RNNs) or long short term memory (LSTM)

RNNs and LSTM may does better than CNNs for this classification task.

'The state of art' are mainly used. If they don't work well, adjust them to our task.

### 2. 1D-CovNets

å…ˆå°è¯•ä½¿ç”¨ 1-DCovNets

ç»“æ„å‚è€ƒ: [https://machinelearningmastery.com/cnn-models-for-human-activity-recognition-time-series-classification/](https://machinelearningmastery.com/cnn-models-for-human-activity-recognition-time-series-classification/)

å½“å‰å°è¯•æ–¹æ¡ˆ:

åˆšå¼€å§‹å°è¯•ä½¿ç”¨äº§ç”Ÿçš„æ•°æ®é‡è¾ƒå¤§ï¼Œç¼–è¯‘çš„æ¨¡å‹éå¸¸å¤æ‚ï¼Œè®­ç»ƒæ—¶é—´éå¸¸é•¿ï¼ˆå…ˆæ”¾å¼ƒå°è¯•äº†ï¼‰

> æŠ˜ä¸­æ–¹æ¡ˆï¼šé€‰æ‹©éšæœºçŠ¶æ€å¤§å°ä¸º 50 ï½ 100ï¼Œ éšæœºç”Ÿæˆçš„æ—¥å¿—é•¿åº¦é™åˆ¶ä¸º 30 ï½ 50ï¼Œ åˆ™é¢„å¤„ç†ç¼–ç åäº§ç”Ÿçš„çŸ©é˜µè¡¨ç¤ºä¸º [1, 50 x (observable_event_set_size + 1)\]
> äº§ç”Ÿçš„æ—¥å¿—ï¼Œç»å¤„ç†åï¼Œåªå‰© 3 ä¸‡å¤šæ¡ï¼Œç”¨äºè®­ç»ƒæ¨¡å‹ã€‚è®­ç»ƒæ—¶é—´å¤§æ¦‚ä¸ºå‡ åˆ†é’Ÿã€‚

![1dcovnet_training_example_01](images/1dconvnet_training_test_01.png)
![1dcovnet_training_example_02](images/1dconvnet_training_test_02.png)

è®¾ç½® ``epochs`` ä¸º 100ï¼Œ è·‘å‡ºæ¥ç»“æœ (è€—è´¹æ—¶é—´ 1 ä¸ªå¤šå°æ—¶)

![1dcovnet_training_example_03](images/1dconvnet_training_test_03_100-epochs.png)

**REMARKS: å½“å‰ç¼–è¯‘æ¨¡å‹æ—¶ä½¿ç”¨çš„ optimizer æ˜¯ adam (SGD çš„ä¸€ä¸ªæ³›åŒ–ç‰ˆ)ï¼Œ è‡³äº batch_size çš„é€‰æ‹©ï¼Œå‚è€ƒ arxiv ä¸Šä¸¤ç¯‡æ–‡çŒ®:**
> 1. [Revisiting Small Batch Training for Deep Neural Networks](https://arxiv.org/abs/1804.07612)
> 2. [Practical recommendations for gradient-based training of deep architectures](https://arxiv.org/abs/1206.5533)
>
> epochs æ•°é€šè¿‡å®éªŒæ¥è¿›è¡Œç¡®å®šï¼Œlearning rate ç»¼åˆ epochs, samples, batch_size å¾—åˆ° error gradient updates (è¯¯å·®æ¢¯åº¦æ›´æ–°) æ•°æ¥ç¡®å®šã€‚
>
> å¯¹äºæ›´æ–°æ•°è¾ƒå¤§çš„ï¼Œé€‰æ‹©å° learning rateï¼ˆè¿™æ—¶ï¼Œepochs æ•°ä¸€èˆ¬ä¸éœ€è¦å¤ªå¤šï¼Œåˆ©ç”¨ early stopping æ—©åœæ³•æ¥è·å¾—æ¨¡å‹æœ€ä½³çš„æ•ˆæœï¼‰, æ›´æ–°æ•°å°çš„ï¼Œé€‰æ‹©å¤§ learning rate (ä¸€èˆ¬éœ€è¦æ›´å¤§çš„ epochs æ•°ï¼Œä»¥è·å¾—åˆé€‚çš„ updates, è®­ç»ƒæ—¶é—´æ›´é•¿)
>
>
> åœ¨ä»£ç å®ç°ä¸­ï¼Œä½¿ç”¨ tf.keras API åªéœ€è¦åœ¨ fit() ä¸­å¼•å…¥ validation set å³å¯è·å¾— history æ•°æ® ï¼ˆæ¯ä¸€ä¸ª epoch çš„è¯„ä¼°å‚æ•°æ•°æ®ï¼‰, ç„¶åé€šè¿‡ç®€å•åœ°ç»˜åˆ¶æˆå›¾ï¼Œå°±èƒ½ç›´è§‚çš„çœ‹åˆ°æƒ…å†µã€‚

#### CNN tuning

è°ƒæ•´ CNN ä¸­è°ƒæ•´çš„è¶…å‚æ•° (hyper-parameters)ã€‚

##### 1. ä¸€æ¬¡éšæ„å°è¯•

å°† ``kernel_size`` ä» ``3`` è°ƒæ•´ä¸º ``5``ï¼Œ ``pool_size`` ä» ``2`` è°ƒæ•´ä¸º ``5``ï¼Œ å¹¶åœ¨æ‹Ÿåˆæ¨¡å‹æ—¶å°†è¾“å…¥çš„è®­ç»ƒé›†åˆ’åˆ†ä¸€éƒ¨åˆ† (0.2) ä½œä¸º validation set (éªŒè¯é›†)ã€‚

![1dcovnet_training_example_04](images/1dconvnet_training_test_03_100-epochs_kernel_pool_size_changed_test_01_model.png)
![1dcovnet_training_example_05](images/1dconvnet_training_test_03_100-epochs_kernel_pool_size_changed_test_01_training_result.png)

Using gpu to reduce time for training.

![](./images/tensorflow_use_gpu_example.png)
![1dcovnet_training_example_06](images/1dconvnet_training_test_03_100-epochs_kernel_pool_size_changed_test_01_training_result_using_gpu.png)

åŠ è½½å·²ä¿å­˜çš„æ¨¡å‹ï¼Œå¹¶ä»åŸå§‹æ—¥å¿—é›†ä¸­é€‰å–è‹¥å¹²æ—¥å¿—è¿›è¡Œæµ‹è¯•ï¼Œæ¥çœ‹æ¨¡å‹æ˜¯å¦èƒ½å¤Ÿé¢„æµ‹å‡ºæ­£ç¡®çš„é”™è¯¯ç±»å‹:

é€‰å–çš„æµ‹è¯•æ—¥å¿— (éœ€è¦ç»è¿‡å‹ç¼©ç¼–ç åï¼Œå†è¾“å…¥ç»™æ¨¡å‹):
![](images/1dconvnet_training_test_03_100-epochs_prediction_test_01_test_logs.png)

é¢„æµ‹æƒ…å†µå¦‚ä¸‹ï¼š
![](images/1dconvnet_training_test_03_100-epochs_prediction_test_01.png)

> NOTICE: å¯ä»¥çœ‹åˆ°ï¼Œæ‰€æœ‰æ—¥å¿—çš„é¢„æµ‹ç»“æœéƒ½æ­£ç¡®ï¼Œä½†ä¹‹å‰å¯¹æ¨¡å‹çš„è®­ç»ƒæ—¶çš„è¯„ä¼°æ¥çœ‹ï¼Œæˆ‘ä»¬é€‰å–çš„æµ‹è¯•æ—¥å¿—ï¼Œå¾ˆå¯èƒ½å°±æ˜¯æ¨¡å‹è®­ç»ƒé›†ä¸­çš„æ ·æœ¬ã€‚
> å› ä¸ºåœ¨æ•°æ®é¢„å¤„ç†æ—¶ï¼Œç”±äºæ¯ç§ç±»åˆ«çš„æ—¥å¿—æ•°é‡ä¸å‡è¡¡ï¼Œè¿›è¡Œäº† over-sampling ä»¥åŠ under-samplingï¼Œ ä¹‹åå†è¿›è¡Œæ‰“ä¹± shuffle, æ‰€ä»¥ä»åŸå§‹çš„æ—¥å¿—ä¸Šçœ‹ï¼Œæ— æ³•çŸ¥é“é‚£äº›æ˜¯æ²¡ç”¨äºè®­ç»ƒçš„æ—¥å¿—ã€‚ï¼ˆé™¤éä¸€å¼€å§‹å°±å°†åŸå§‹æ•°æ®è¿›è¡Œåˆ’åˆ†ï¼‰
>
> ä»æ¨¡å‹è¯„ä¼°æ—¶æ¨¡å‹åœ¨æµ‹è¯•æ•°æ®é›†ä¸Šçš„è¡¨ç° (å‡†ç¡®ç‡ 77% å·¦å³)æ¥çœ‹ï¼ŒåŸºæœ¬ç¡®å®šæˆ‘ä»¬é€‰å–ç”¨äºæµ‹è¯•çš„æ•°æ®åº”è¯¥å°±æ˜¯åŒ…å«äºå®ƒçš„è®­ç»ƒæ•°æ®é›†ä¸­ã€‚ğŸ¤”

##### 2. tuning number of filters

å°è¯•è°ƒæ•´ ``filters`` æ•°é‡ (äº§ç”Ÿçš„ feature map æ•°é‡)ï¼Œå°†ç½‘ç»œä¸­æ‰€æœ‰ hyperparameters è°ƒæ•´ä¸ºåŸå§‹é»˜è®¤å‚æ•°ï¼Œå¹¶å°† ``epochs`` ä¸‹è°ƒè‡³ ``10``ï¼Œå‡å°è¿­ä»£æ¬¡æ•°ï¼ˆå‡å°‘è®­ç»ƒæ‰€éœ€çš„æ—¶é—´ï¼‰
> ä¸ºäº†æ¢ç´¢åˆé€‚çš„ ``filters`` å¤§å°ï¼Œæˆ‘ä»¬å¯ä»¥é€‰å–ä¸€ä¸ªèŒƒå›´ï¼Œå°äºåˆå§‹å€¼ ``64``çš„å’Œå¤§äºåˆå§‹å€¼çš„ã€‚

![](images/1dconvnet_training_test_04_filters_tuning_01.png)
> å®Œæˆæµ‹è¯•ï¼Œè€—è´¹å¤§æ¦‚ 3 ä¸ªå¤šå°æ—¶ã€‚ å›¾ä¸­ï¼Œaccuracy å‡†ç¡®ç‡æ˜¯ mean å‡å€¼ï¼Œåé¢è·Ÿç€çš„æ˜¯ std (standard deviation) æ ‡å‡†å·®ã€‚

![](images/1dconvnet_training_test_04_filters_tuning_exp_cnn_filters.png)
> ä»ä¸Šå›¾å¯ä»¥çœ‹åˆ°ï¼Œéšç€ ``filters`` feature map çš„æ•°é‡çš„å¢åŠ ï¼Œæµ‹è¯•å‡†ç¡®ç‡ä¸­å€¼ï¼ˆé»„è‰²çš„çº¿ï¼‰åœ¨ä¸æ–­ä¸Šå‡ï¼Œè€Œåœ¨ ``64`` ä¹‹ååè€Œå¼€å§‹ä¸‹é™ï¼Œå› æ­¤ï¼Œæˆ–è®¸ ``64`` å°±æ˜¯åˆé€‚çš„å€¼ï¼Œå®ƒåŒæ—¶å…·å¤‡æ€§èƒ½å’Œç¨³å®šæ€§ã€‚
>
> è¿™ä¹ˆçœ‹ï¼Œæ¨¡å‹åˆšå¼€å§‹é€‰æ‹©çš„ ``64`` å°±æ˜¯æ¯”è¾ƒåˆé€‚çš„å€¼ã€‚ã€‚ã€‚

##### 3. tuning kernel size

è°ƒæ•´ ``kernel`` (å·ç§¯çš„æ ¸æˆ– filter è¿‡æ»¤å™¨å¤§å°)ï¼Œæ ¸çš„å¤§å°æ§åˆ¶æ¯æ¬¡è¯»å–åºåˆ—æ—¶è¦è€ƒè™‘çš„æ—¶é—´æ­¥é•¿ (time steps), ç„¶åå°†æ—¶é—´æ­¥é•¿æŠ•å½± (project) åˆ° feature map (ç‰¹å¾æ˜ å°„ï¼Œæ­¤è¿‡ç¨‹ä¸ºå·ç§¯)ã€‚è¾ƒå¤§çš„æ ¸æ„å‘³ç€å¯¹è¾“å…¥è¯»å–ä¸é‚£ä¹ˆä¸¥æ ¼ã€‚
> åŒæ ·ï¼Œæˆ‘ä»¬å¯ä»¥é€‰æ‹©ä¸€ä¸ªèŒƒå›´çš„ ``kernel_size`` æ¥è¿›è¡Œæµ‹è¯•ï¼Œå…¶ä¸­åŒ…å«åˆå§‹å»ºç«‹ç½‘ç»œé€‰æ‹©çš„å€¼ ``3``ã€‚

![](./images/1dconvnet_training_test_05_kernel_size_01.png)
> å®Œæˆæµ‹è¯•ï¼Œæ‰€èŠ±è´¹çš„æ—¶é—´è¿˜æ˜¯ 3 ä¸ªå¤šå°æ—¶ï¼Œæµ‹è¯•é›†å‡†ç¡®ç‡æ˜¯ mean å‡å€¼ï¼Œåé¢æ˜¯æ ‡å‡†å·®ã€‚

![](images/1dconvnet_training_test_05_kernel_size_01_exp_cnn_kernel.png)
> ä»è¯¥ç›’å½¢å›¾ä¸­å¯ä»¥æ˜æ˜¾çœ‹å‡ºï¼Œéšç€ ``kernel_size`` çš„å¢åŠ ï¼Œæµ‹è¯•å‡†ç¡®ç‡ä¸­å€¼ï¼ˆé»„è‰²çº¿ï¼‰ä¸æ–­ä¸Šå‡ï¼Œä¸”æ‰€æœ‰è¶…å‚æ•°å–å€¼å¯¹åº”çš„æµ‹è¯•å‡†ç¡®ç‡ç¨³å®šæ€§éå¸¸å¥½ã€‚
>
> ä»æµ‹è¯•æ¥çœ‹ï¼Œ``kernel_size`` å– ``11`` å…·æœ‰éå¸¸ä¸é”™çš„æ•ˆæœã€‚
>
> NOTICE: ä»å›¾ä¸Šçœ‹ï¼Œä¼¼ä¹æˆ‘ä»¬è¿˜å¯ä»¥å°è¯•å–ä¸€ä¸ªæ¯” ``11`` è¿˜å¤§çš„èŒƒå›´æ¥è¿›è¡Œæµ‹è¯•ï¼Œçœ‹èƒ½å¦è·å¾—æ›´å¥½çš„æ•ˆæœã€‚
>
> REMARKS: åŸå› åˆ†æï¼šæˆ‘ä»¬çŸ¥é“ kernel size å·ç§¯æ ¸çš„å¤§å°æ˜¯ç¡®å®šæ—¶é—´æ­¥é•¿çš„å¤§å°ï¼Œå½±å“çš„æ˜¯å¯¹è¾“å…¥åºåˆ—æ¶ˆæ¯çš„è¯»å–ï¼Œä»æ•ˆæœä¸Šçœ‹ï¼Œéšç€ kernel size çš„å¢å¤§ï¼Œæ¨¡å‹æ•ˆæœè¶Šå¥½ã€‚å¯èƒ½åŸå› æ˜¯ï¼Œè¾“å…¥çš„æ•°æ®ä»åŸå§‹æ•°æ®ç»è¿‡ç¼–ç è¡¨ç¤ºåï¼Œæ˜¯ä¸€ä¸ªç»´åº¦è¾ƒé«˜ä¸”éå¸¸ç»†ç¨€ç–çš„ tensorã€‚é€‚å½“å¢å¤§ kernel size åè€Œèƒ½å¤Ÿæ›´å¥½å¤„ç†è¿™æ ·çš„æ•°æ®ã€‚

ä½¿ç”¨æ¯”ä¸Šé¢ ``11`` æ›´å¤§çš„ä¸€ä¸ªèŒƒå›´å†æ¬¡è¿›è¡Œæµ‹è¯•ï¼Œç»“æœå¦‚ä¸‹:

![](./images/1dconvnet_training_test_05_kernel_size_02.png)
> è€—æ—¶ 3 ä¸ªå¤šå°æ—¶ï¼Œå¯ä»¥çœ‹åˆ°ï¼Œæµ‹è¯•ç²¾å‡†ç‡å‡å€¼éƒ½éå¸¸é«˜ï¼Œä¸”å®ƒä»¬çš„ç¨³å®šæ€§éƒ½å¾ˆå¥½ã€‚

![](./images/1dconvnet_training_test_05_kernel_size_02_exp_cnn_kernel.png)
> ä»è¯¥å›¾ä¸­çœ‹çš„è¯ï¼Œ``kernel`` å– ``19`` æ˜¯æœ€å¥½çš„ã€‚
>
> å› ä¸ºï¼Œéšç€ kernel size çš„å¢åŠ ï¼Œæµ‹è¯•ç²¾å‡†ç‡ä¸­å€¼ï¼ˆé»„è‰²çº¿ï¼‰ä¸æ–­ä¸Šå‡ï¼Œæ„å‘³ç€ï¼Œå¯èƒ½è¿˜æœ‰ä¸Šå‡ç©ºé—´ï¼Œå› æ­¤å¯ä»¥å†æ¬¡è®¾è®¡å®éªŒäº†æµ‹è¯•ä¸€ç»„æ›´å¤§çš„ kernel sizeã€‚

![](./images/1dconvnet_training_test_05_kernel_size_03.png)
> è€—è´¹ 5 ä¸ªå¤šå°æ—¶ï¼Œéšç€ kernel size çš„å¢å¤§ï¼Œè®­ç»ƒæ—¶é—´å˜é•¿ã€‚

![](./images/1dconvnet_training_test_05_kernel_size_03_exp_cnn_kernel_03.png)
> ä»å›¾ä¸­ï¼Œå¯ä»¥çœ‹åˆ°ï¼Œéšç€ kernel size çš„å¢å¤§ï¼Œæµ‹è¯•é›†ç²¾å‡†ç‡ä¸­å€¼ï¼ˆé»„è‰²çº¿ï¼‰ä¸æ–­ä¸Šå‡ï¼Œè™½ç„¶å›¾ä¸­æœ‰äº›è®¸ç¦»ç¾¤ç‚¹ (outlines)ã€‚
>
> è¡¨ç°æœ€å¥½çš„æ˜¯ ``27`` å¤§å° kernel size çš„æƒ…å†µã€‚
>
> ä»ä¸Šå›¾çœ‹ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥å†æ¬¡è®¾è®¡ä¸€ä¸ªæ›´å¤§çš„èŒƒå›´è¿›è¡Œå®éªŒã€‚ã€‚ã€‚


![](./images/1dconvnet_training_test_05_kernel_size_04.png)
> è€—æ—¶å°†è¿‘ 4 ä¸ªå°æ—¶ã€‚

![](./images/1dconvnet_training_test_05_kernel_size_04_exp_cnn_kernel_04.png)
> ç›¸æ¯”äºä¹‹å‰çš„å€¼ ``27``, é™¤äº† ``29`` æœ‰ä¸¤ä¸ªè¡¨ç°ä¸æ˜¯å¾ˆå¥½çš„ç¦»ç¾¤ç‚¹å¤–ï¼Œå…¶ä»–çš„æ‰€æœ‰æµ‹è¯•ç»“æœéƒ½æ¯” ``27`` çš„è¦å¥½ï¼Œè¿™æ¬¡æµ‹è¯•ä¸­è¡¨ç°æœ€å¥½çš„æ˜¯ ``37``ã€‚
>
> è¿™ä¹ˆçœ‹ï¼Œæˆ‘ä»¬è¿˜æ˜¯å¯ä»¥å†è®¾è®¡å®éªŒæ¥æ¢ç´¢æ›´å¥½çš„ kernel size å–å€¼ã€‚

![](./images/1dconvnet_training_test_05_kernel_size_05.png)
> è€—æ—¶ 5 ä¸ªå¤šå°æ—¶ã€‚

![](./images/1dconvnet_training_test_05_kernel_size_05_exp_cnn_kernel_05.png)
> ä»å®éªŒæ•°æ®ä¸Šçœ‹çš„è¯ï¼Œå®ƒä»¬çš„è¡¨ç°æ•ˆæœéƒ½æŒºä¸é”™ï¼ˆä½† 50% ç‚¹ï¼Œå³é»„è‰²çº¿ä» 41 å¼€å§‹é€æ¸ä¸‹é™äº†ï¼‰
>
> åç»­æ›´å¤§çš„å–å€¼èŒƒå›´å®éªŒå°±ä¸åšäº†ï¼Œä¼°è®¡ä¹Ÿä¸ä¼šå†æœ‰å¾ˆå¤§çš„æå‡äº†ã€‚


ä»å¯¹ kernel size çš„æµ‹è¯•ç»“æœæ¥çœ‹ï¼Œkernel size å– ``31``, ``37``, ``39``, ``41``, ``43`` éƒ½ä¸é”™çš„é€‰æ‹©ã€‚
> æˆ‘ä»¬å¯ä»¥åœ¨é€‰æ‹©è¿™äº› kernel size çš„æƒ…å†µä¸‹ï¼Œæ¥æ¢ç´¢ ``filters`` çš„å…¶ä»–å¯èƒ½å–å€¼ï¼ˆå½“å‰ä½¿ç”¨çš„ 64ï¼‰ï¼Œæ¥çœ‹æœ‰æ²¡æœ‰æ›´å¥½çš„æ•ˆæœã€‚

###### re-Testing filters

åœ¨é€‰æ‹©ä¸Šé¢è·å¾—è¾ƒå¥½æ•ˆæœçš„ kernel size çš„æƒ…å†µä¸‹ï¼Œå†æ¬¡è°ƒæ•´ filters çš„æ•°é‡ï¼Œçœ‹èƒ½å¦è·å¾—æ›´å¥½çš„æ•ˆæœã€‚

1. é’ˆå¯¹ä¸ kernel_size = ``31``, filters æµ‹è¯•èŒƒå›´ ``[8, 16, 32, 48]``

![](./images/1dconvnet_training_test_04_filters_tuning_02.png)
> å¤§æ¦‚ 4 ä¸ªå°æ—¶ã€‚

![](./images/1dconvnet_training_test_04_filters_tuning_exp_cnn_filters__kernel_size=31_01.png)
> å¯ä»¥çœ‹åˆ°ï¼Œè™½ç„¶ç›¸æ¯” ``filters=64`` çš„æ•ˆæœæ˜¯å·®äº†ç‚¹ï¼Œä½†æ˜¯æ˜æ˜¾å¯ä»¥äº†è§£åˆ°åœ¨ ``kernel_size=31`` çš„æƒ…å†µä¸‹ï¼Œå°±ç®— feature map çš„æ•°é‡å«å°‘ï¼Œæ¨¡å‹è¿˜èƒ½ä¿æŒä¸é”™çš„æ•ˆæœã€‚**ä¸€ä¸ªè¶‹åŠ¿æ˜¯éšç€ filters çš„å¢åŠ ï¼Œæµ‹è¯•ç²¾å‡†ç‡ä¸­å€¼ (é»„è‰²çº¿)ä¸æ–­ä¸Šå‡ï¼Œè¿™æ„å‘³ç€æé«˜ filters å–å€¼æ˜¯èƒ½å¤Ÿæé«˜æ¨¡å‹çš„æ€§èƒ½çš„**
>
> æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥è¯•è¯•å¦‚æœæé«˜ filters çš„å–å€¼ï¼Œæ¨¡å‹èƒ½å¦è·å¾—æ›´å¥½çš„æ•ˆæœã€‚

![](./images/1dconvnet_training_test_04_filters_tuning_exp_cnn_filters__kernel_size=31_02.png)
![](./images/1dconvnet_training_test_04_filters_tuning_exp_cnn_filters__kernel_size=31_02_1.png)
![](./images/1dconvnet_training_test_04_filters_tuning_exp_cnn_filters__kernel_size=31_02_2.png)
> æœ¬æ¥æ˜¯ç”¨åŒ…å« ``256`` çš„ï¼Œä½†æ˜¯å‰ä¸‰ä¸ªé¡¹è·‘ï¼Œå·²ç»èŠ±äº† 9 ä¸ªå¤šå°æ—¶ï¼Œè€Œæ ¹æ® ``256`` ä¸­ä¸€æ¬¡ epoch æ‰€éœ€çš„æ—¶é—´æ¥çœ‹ï¼Œå®ƒä¼°è®¡æœ€å°‘éœ€è¦ 7 ä¸ªå°æ—¶ã€‚
>
> ä»ç¬¬ä¸€æ¬¡å®Œæ•´è®­ç»ƒæ•ˆæœæ¥çœ‹ï¼Œä¹Ÿä¼°è®¡ä¸ä¼šå¤ªå¥½çš„æ•ˆæœï¼Œæ‰€ä»¥ä¸è·‘äº†ã€‚


**éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œä¸Šé¢çš„æ‰€æœ‰è°ƒä¼˜éƒ½æ˜¯å›ºå®šå…¶ä»– hyper-parameter, ç„¶åå†æ¢ç´¢æŸä¸ªå‚æ•°çš„æœ€ä¼˜å€¼ï¼Œæœ€åç»„åˆå½¢æˆçš„æ•ˆæœå¯èƒ½å¹¶ä¸æ˜¯çœŸæ­£çš„æœ€ä¼˜ã€‚**

**ä¾‹å¦‚ï¼šå¤šä¸ªå‚æ•°ä¸€èµ·å¯ä»¥å½¢æˆä¸åŒçš„ç»„åˆï¼Œ(å¦‚åœ¨ç¡®å®šäº†æœ€ä¼˜ kernel size åï¼Œå†æ¬¡çœ‹åœ¨ä¸åŒ filters ä¸‹æ­¤ kernel size çš„æ•ˆæœ) ç­‰ç­‰ã€‚ä¸”å®éªŒä¸­ï¼Œæµ‹è¯•æ˜¯é‡å¤ 10 æ¬¡æ¥çœ‹ç¨³å®šæ€§ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥é€‚å½“æé«˜é‡å¤æ¬¡æ•°ï¼Œå†çœ‹çœ‹ç¨³å®šæ€§ã€‚**

#### Applying models defined above to more complicate task

ä½¿ç”¨ä¹‹å‰æ¢ç´¢å‡ºæ¥çš„æ¨¡å‹ç»“æ„ï¼Œåº”ç”¨åˆ°æ—¥å¿—å‹ç¼©å¤„ç†è¡¨ç¤ºæ›´é•¿çš„æƒ…å†µ (ä¹‹å‰æ˜¯ 50 ç¼–ç åæœ€é•¿è¡¨ç¤ºä¸º 600, ä¸‹é¢ä½¿ç”¨çš„æ˜¯ 100, ç¼–ç åæœ€é•¿è¡¨ç¤ºä¸º 1400)ã€‚

![](./images/1dconvnet_training_arch_fd1dconvnet_100-length-log_01.png)
![](./images/1dconvnet_training_arch_fd1dconvnet_100-length-log_01_test.png)
> æ¨¡å‹ä»èƒ½è¡¨ç¤ºå‡ºä¸é”™çš„æ•ˆæœï¼Œéœ€è¦æ³¨æ„çš„æ˜¯è™½ç„¶æ—¥å¿—çš„è¡¨ç¤ºé•¿åº¦ä¸åŒï¼Œä½†å®ƒä»¬çš„æ—¥å¿—ç¼–ç æ˜ å°„ (encoding mapping) çš„æœ€é•¿è¡¨ç¤ºæ˜¯æ¥è¿‘çš„ã€‚ï¼ˆå› ä¸ºå®ƒä»¬ DFA çš„ observable events set çš„å¤§å°ç›¸è¿‘ï¼‰
>
> å³å®ƒä»¬çš„æ—¥å¿—ç¼–ç è¿‡åï¼Œä½¿ç”¨çš„ vector è¡¨ç¤ºçš„ç¨€ç–ç¨‹åº¦ç›¸è¿‘ã€‚(é€šè¿‡ä¹‹å‰çš„æµ‹è¯•ï¼Œå¦‚æœé‡åˆ°æœ‰æ›´é•¿ encoding mapping çš„æƒ…å†µï¼Œå¯é€‚å½“æé«˜ kernel size çš„å¤§å°ï¼Œå†å¯¹kernel size è¿›è¡ŒèŒƒå›´å–å€¼æµ‹è¯•ï¼Œæµ‹è¯•ä¸åŒæ›´å¤§å–å€¼æƒ…å†µä¸‹çš„æ€§èƒ½å’Œç¨³å®šæ€§)

> NOTICE: å­˜åœ¨çš„ä¸€ä¸ªé—®é¢˜ï¼Œç”±äºå½“å‰é‡‡ç”¨çš„ over sampling / under sampling å¤„ç†æ˜¯åœ¨å¤„ç†åŸå§‹æ—¥å¿—æ•°æ®çš„æ—¶å€™ï¼Œå› æ­¤åœ¨åˆ†æ‰¹æ¬¡å­˜æ”¾å·²å¤„ç†å¹¶å‹ç¼©åçš„æ—¥å¿—æ•°æ®åï¼Œå¦‚æœä¸æ˜¯ä½¿ç”¨æ‰€æœ‰æ•°æ®æ–‡ä»¶æ¥å¯¹æ¨¡å‹è¿›è¡Œè®­ç»ƒçš„è¯ï¼Œè¯»å–è‹¥å¹²ä¸ªæ–‡ä»¶ï¼Œä»å¯èƒ½å‡ºç° imbalance é—®é¢˜ã€‚
> REMARKS: ä»å½“å‰æ¨¡å‹çš„è®­ç»ƒçš„è¡¨ç°æ¥çœ‹ï¼Œåº”è¯¥è€ƒè™‘å°† over-sampling / under sampling å¤„ç†æ”¾åˆ°æ¨¡å‹è®­ç»ƒä¹‹å‰ï¼Œè¯»å–è®­ç»ƒæ•°æ®ä¹‹åï¼Œè¿™æ ·æ›´åˆç†ã€‚
>
> Code Refactoring is needed.

![](./images/1dconvnet_training_arch_fd1dconvnet_100-length-log_01_multi_dataset_file.png)


#### Multi-Channel (head) CNN

multi-head cnn ï¼ˆé€‰æ‹©ä¸åŒ kernel size çš„ conv å±‚åš feature map çš„æå–ï¼Œåœ¨ flatten å±‚ä¹‹åå†å°†å®ƒä»¬å…¨éƒ¨ concatenate æ‹¼æ¥åœ¨ä¸€èµ·ï¼‰

##### 1. ç®€å•å°è¯•

ç½‘ç»œç»“æ„å¦‚ä¸‹:

![](./images/1dconvnet_training_multi_head_01_multi_channel_01.png)
> ä¸‰ä¸ª head ä½¿ç”¨ filters å‡ä¸º ``64``, ä½¿ç”¨çš„ kernel size åˆ†åˆ«ä¸º ``15``, ``17``, ``19``ï¼Œä¸”åªæœ‰ä¸€å±‚å·ç§¯å±‚ã€‚pool_size å‡ä¸º ``2``ï¼Œ ``dropout`` éƒ½æ˜¯ ``0.5``ã€‚

ç”±äºæ˜¯ä¸€æ¬¡éšæ„çš„å°è¯•ï¼Œå…ˆä¸è€ƒè™‘è®­ç»ƒå‡ºæ¥çš„æ¨¡å‹çš„ç¨³å®šæ€§ï¼Œä¼˜å…ˆè€ƒè™‘æ€§èƒ½ï¼Œåªåšä¸€æ¬¡è®­ç»ƒï¼Œç»“æœå¦‚ä¸‹:
![](./images/1dconvnet_training_multi_head_01_multi_channel_01_test.png)
> è®­ç»ƒ 10 epochs åï¼Œå¯ä»¥çœ‹åˆ°æ•ˆæœè¿˜è¡Œï¼Œä¼°è®¡è¿˜æœ‰å¾ˆå¤§æå‡ç©ºé—´ï¼Œå¯ä»¥åœ¨å¯¹ç½‘ç»œçš„ç»“æ„è¿›è¡Œè°ƒæ•´ã€‚

##### 2. multi-channel with 2 conv layers

è°ƒæ•´ä¸Šé¢çš„ç½‘ç»œç»“æ„ï¼Œä½¿ç”¨ä¸¤å±‚å·ç§¯å±‚ï¼Œå¹¶è°ƒæ•´ä¸‰ä¸ªä¸åŒ head çš„ kernel size ä¸º ``17``, ``19``, ``21``ã€‚

![](./images/1dconvnet_training_multi_head_02_multi_channel.png)

è®­ç»ƒç»“æœå¦‚ä¸‹:

![](./images/1dconvnet_training_multi_head_02_multi_channel_test.png)
> æ•ˆæœå…¶å®å’Œåªä½¿ç”¨ä¸€ä¸ª head (kernel size ä¸º 17ï¼Œ 19ï¼Œ æˆ–è€… 21) çš„ 1dconvnet çš„æ•ˆæœè¡¨ç°å…¶å®å·®ä¸å¤šã€‚
>
> REMARKS: åç»­æµ‹è¯•å¯ä»¥æµ‹è¯•ç¨³å®šæ€§ï¼Œä»¥åŠå¯¹ä¸åŒçš„ head çš„ kernel size å†ä½œå‡ºè°ƒæ•´ã€‚

**NOTICE: ç½‘ç»œç»“æ„å˜å¤æ‚åï¼Œæ¨¡å‹æ‹Ÿåˆè¾¾åˆ°å¥½çš„æ•ˆæœï¼Œæ‰€éœ€çš„æ•°æ®é‡ä¼šå¤§å¹…åº¦å¢åŠ ï¼Œå› æ­¤æˆ‘ä»¬è¿˜å¯ä»¥å°è¯•é€‚å½“å¢åŠ  epochs çš„æ•°é‡ (ä»¥ä¸Šå®éªŒä¸­ä½¿ç”¨ epoch æ•°é‡éƒ½æ§åˆ¶åœ¨ 10 å·¦å³ï¼Œä¸»è¦æƒ³å¿«é€Ÿè¡¡é‡æ¨¡å‹çš„ä¼˜ç§€ç¨‹åº¦)**

ä¸‹é¢ç»™å‡ºçš„æ˜¯ï¼Œä¸€äº›ç½‘ç»œç»“æ„è°ƒæ•´è¿‡åçš„æµ‹è¯•ä¸€æ¬¡æµ‹è¯•ç»“æœï¼ˆepochs ä¸å®šï¼‰

![](./images/1dconvnet_training_multi_head_03_multi_channel_02.png)
![](./images/1dconvnet_training_multi_head_03_multi_channel_02_test.png)

![](./images/1dconvnet_training_multi_head_04_multi_channel_03.png)
![](./images/1dconvnet_training_multi_head_04_multi_channel_03_test.png)

![](./images/1dconvnet_training_multi_head_05_multi_channel_04.png)
![](./images/1dconvnet_training_multi_head_05_multi_channel_04_test.png)

![](./images/1dconvnet_training_multi_head_06_multi_channel_05.png)
![](./images/1dconvnet_training_multi_head_06_multi_channel_05_test.png)

é€‰æ‹©ä¸Šé¢æ¢ç´¢å‡ºæ¥çš„æ¯”è¾ƒå¥½çš„ filters å’Œ kernel size çš„å–å€¼ï¼Œè¿›è¡Œç»„åˆã€‚

![](./images/1dconvnet_training_multi_head_07_multi_channel_06.png)
![](./images/1dconvnet_training_multi_head_07_multi_channel_06_test.png)
> æ•ˆæœæ˜¯å¥½äº†ä¸€ç‚¹ã€‚

![](./images/1dconvnet_training_multi_head_08_multi_channel_07.png)
![](./images/1dconvnet_training_multi_head_08_multi_channel_07_test.png)
> è¿™æ¬¡è®­ç»ƒä¸­é€‰æ‹©çš„ kernel size ç»„åˆä¹Ÿæ˜¯ä»ä¸Šé¢å®éªŒè·å¾—çš„ä¸é”™çš„å–å€¼ï¼Œç„¶åä¹Ÿå¯¹æµ‹è¯•é›†è¿›è¡Œäº†ä¿®æ”¹ï¼ˆå¢åŠ åˆ°äº† 0.2 å³ 20%ï¼Œ ä¹‹å‰æ˜¯ 0.1ï¼‰

ä½¿ç”¨ validation set å¹¶æ”¶é›†è®­ç»ƒæ—¶çš„æ•°æ®ï¼Œç»˜åˆ¶å›¾å½¢ã€‚
![](./images/1dconvnet_training_multi_head_09_multi_channel_08_with_val_and_plot_statistics.png)
![](./images/1dconvnet_training_multi_head_09_multi_channel_08_fd1dconvnet_multichannel_fig.png)
> è¡¨æ˜è¯¥æ¨¡å‹å½“å‰ä½¿ç”¨çš„è¶…å‚æ•°å·²ç»æ˜¯æŒºä¸é”™çš„äº†ã€‚
>
> å¯å†è®¾è®¡ä¸€ä¸ª epochs æ•°é‡æ›´å¤§çš„å®éªŒæ¥åšå¯¹æ¯” (çœ‹ä»€ä¹ˆæ—¶å€™å¼€å§‹æ¨¡å‹å¼€å§‹è¿‡æ‹Ÿåˆ, over-fitting)ã€‚

### 3. RNNs

#### Simple RNN or GRN

#### LSTM

å¯å…ˆå°è¯•åªä½¿ç”¨ LSTM çš„æ–¹æ¡ˆã€‚

![](./images/1dconvnet_training_arch_fdlstmnet_01_try.png)
> è®­ç»ƒå‡ºæ¥çš„æ¨¡å‹æ•ˆæœéå¸¸å·®ï¼Œæ ¹æœ¬æ²¡æœ‰æ‹Ÿåˆè®­ç»ƒæä¾›çš„æ•°æ®, ä¸”è®­ç»ƒæ—¶é—´éå¸¸é•¿, 1 epoch éœ€è¦åå‡ åˆ†é’Ÿã€‚
> åç»­éœ€è¦å¯¹ç»“æ„è¿›è¡Œè°ƒæ•´ã€‚

å°è¯• CNN ä¸­æ·»åŠ  LSTM å±‚çš„ç»“æ„ã€‚

![](./images/1dconvnet_training_arch_fdcnnlstmnet1.png)]
![](./images/1dconvnet_training_arch_fdcnnlstmnet1_01.png)
![](./images/1dconvnet_training_arch_fdcnnlstmnet1_02.png)
> ä»¥ä¸Šå°è¯•å‡ä¸è¡Œï¼Œæ¨¡å‹æ‹Ÿåˆæ•ˆæœéå¸¸ä¸å¥½ 20% å·¦å³ã€‚
>
ä¸Šé¢çš„è¿™äº›ç»“æ„ï¼Œå¯èƒ½éœ€è¦è€ƒè™‘è°ƒæ•´ç»“æ„åå†è¿›è¡Œæµ‹è¯•ã€‚

å‚è€ƒ arxiv ä¸Šçš„ä¸¤ç¯‡æ–‡çŒ®ä¸­æåˆ°å†…å®¹ï¼Œè°ƒæ•´ CNN ä»¥åŠ Dense å±‚ä¸­çš„ä½¿ç”¨ activation function (æ¿€æ´»å‡½æ•°), ä½¿ç”¨ elu æˆ– selu æ¥æå‡ cnn ä¸­è®­ç»ƒçš„é€Ÿåº¦ï¼Œæé«˜ç²¾å‡†ç‡ accuracyã€‚ ä½¿ç”¨è¿™äº› relu çš„ alternation è¿˜å¯ä»¥é¿å… vanishing gradient æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼Œ ï¼ˆä¹‹å‰å¸¸ä½¿ç”¨ relu é…åˆ kernel_initializer æ¥åš relu çš„åˆå§‹ weights èµ‹å€¼ï¼‰

> 1. [Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)](https://arxiv.org/abs/1511.07289)
> 2. [Self-Normalizing Neural Networks](https://arxiv.org/abs/1706.02515)

> More details should go into above papers. issues like what drawbacks they introduced.
>
> TODO: The above papers needs to be read in more detail.


![](./images/1dconvnet_training_arch_fdcnnlstmnet1_03.png)
![](./images/1dconvnet_training_arch_fdcnnlstmnet1_03_test.png)

> å¯ä»¥çœ‹åˆ°ï¼Œä» ç¬¬ 6,7 epoch å¼€å§‹ï¼Œæ¨¡å‹å¼€å§‹æ‹Ÿåˆè®­ç»ƒæ•°æ®ã€‚


#### Full CNNs with LSTM 

> reference: on arxiv
> [Multivariate LSTM-FCNs for Time Series Classification](https://arxiv.org/abs/1801.04503)
>
> TODO: this paper should be read in more detail

![](./images/1dconvnet_training_arch_fdcnnlstmnet2.png)
![](./images/1dconvnet_training_arch_fdcnnlstmnet2_test.png)

![](./images/1dconvnet_training_arch_fdcnnlstmnet2_01.png)
![](./images/1dconvnet_training_arch_fdcnnlstmnet2_01_test.png)
> ä¿®æ”¹ kernel size åè¿›è¡Œçš„æµ‹è¯•ï¼Œä»æœ‰ä¸é”™çš„æ•ˆæœã€‚

> è¿™æ˜¯ä¸€ä¸ªå¯è¡Œçš„æ–¹æ¡ˆï¼Œä½†ä»ä¹‹å‰çš„æµ‹è¯•æ¥çœ‹ï¼Œåªä½¿ç”¨ cnn å·ç§¯å±‚ä¹Ÿæ˜¯èƒ½å¤Ÿè·å¾—éå¸¸ä¸é”™çš„æ•ˆæœçš„ï¼Œæ‰€æœ‰å¾ˆéš¾åˆ¤æ–­æ­¤æ¨¡å‹ä¸­å³è¾¹ LSTM å±‚åœ¨æ¨¡å‹ä¸­è´¡çŒ®åº¦åˆ†é…çš„é—®é¢˜ä¸Šæœ‰èµ·åˆ°å¤šå°‘ä½œç”¨ã€‚
>
> åªä½¿ç”¨ä¸‰å±‚å·ç§¯å±‚å åŠ ï¼ˆç»“æ„çš„å·¦è¾¹éƒ¨åˆ†ï¼‰æ¥æ„å»ºæ¨¡å‹ï¼Œä¸å®ƒè¿›è¡Œå¯¹æ¯”çœ‹çœ‹ã€‚

![](./images/1dconvnet_training_arch_fd1dconvnet_m_01.png)
![](./images/1dconvnet_training_arch_fd1dconvnet_m_01_test.png)
> è¯¥ç»“æ„è¡¨ç°å‡ºçš„æ•ˆæœä¸ä¸Šé¢çš„åŒé€šé“çš„æ•ˆæœå¾ˆç›¸è¿‘ã€‚

> è¯¥æ¨¡å‹å€¼å¾—è€ƒè™‘ã€‚ æœ‰éå¸¸å¤§çš„æ¦‚ç‡ LSTM æ²¡æœ‰æ‹Ÿåˆè®­ç»ƒæ•°æ®ã€‚

## Issues

### data representations

å¦‚ä½•æ›´å¥½çš„è¡¨ç¤ºæ—¥å¿—è§‚å¯Ÿåºåˆ—ï¼Ÿ

å½“å‰é—®é¢˜ï¼Œå³å¦‚ä½•ä½¿ç”¨æ•°æ®ï¼Œè¡¨ç¤ºæ•°æ® (è¡¨ç¤ºå­¦ä¹ ï¼ŒRepresentation learning), ç‰¹å¾å·¥ç¨‹ (feature engineering)ã€‚

å¯ä»¥å…ˆå°è¯•è‡ªå·±ä½¿ç”¨ä¼ ç»Ÿçš„æœºå™¨å­¦ä¹ æ–¹æ³•ï¼Œç”¨ MLP (multi-layer Perceptron network) å‰é¦ˆç½‘ç»œæ¥è¿›è¡Œå®éªŒã€‚ä¹‹åå†å‚è€ƒä»–äººåº”ç”¨äºæ–‡æœ¬åºåˆ—åˆ†ç±»çš„æ¨¡å‹ï¼ˆé€šå¸¸æ˜¯æ·±åº¦å­¦ä¹ æ–¹æ³•ï¼Œå³è®©æ¨¡å‹è‡ªåŠ¨åšè¡¨ç¤ºå­¦ä¹ ï¼Œè‡ªåŠ¨æŠ½å–é«˜å±‚ç‰¹å¾ï¼‰ã€‚

> æ”¾å¼ƒå°è¯•æ‰‹åŠ¨è¿›è¡Œç‰¹å¾æŠ½å–çš„æ–¹å¼ï¼Œä¾‹å¦‚å¯¹äºæ–‡æœ¬åˆ†ç±»çš„ä¼ ç»Ÿå¤„ç†æ–¹å¼ï¼ŒBow (Bag of words) éœ€å…·å¤‡ä¸€å®šçš„ä¸“ä¸šçŸ¥è¯†ä¸“å®¶æ‰èƒ½æ¥å®šæ‰€è¦ä½¿ç”¨çš„ vocabularyã€‚ Word Embedding (è¯åµŒå…¥) ä¹Ÿæ˜¯æœ‰ç±»ä¼¼çš„é—®é¢˜ã€‚

å‚è€ƒ **A Compact Encoding for Efficient Character-level Deep Text Classification-marinho2018** ä¸­ Character-Level (å­—ç¬¦çº§åˆ«) ç´§å‡‘ç¼–ç æ¥å¤„ç†è¾“å…¥çš„æ—¥å¿—ä¸­çš„è§‚å¯Ÿã€‚ä¹‹åå†è€ƒè™‘é…åˆ CNNs æˆ– RNNs æˆ–è€… LSTM (Long Short Term Memory) æ¨¡å‹æ¥è®­ç»ƒã€‚

> 1. [A Compact Encoding for Efficient Character-level Deep Text Classification](https://ieeexplore.ieee.org/document/8489139)
> 2. [Character-Level neural networks for short text classification](https://ieeexplore.ieee.org/document/8090812)

### Imbalanced dataset

äº§ç”Ÿçš„æ—¥å¿—ç±»åˆ«æ•°é‡ä¸å¹³è¡¡é—®é¢˜ï¼Œå¦‚ä½•è§£å†³ï¼Ÿ

å¯¹æ•°é‡è¾ƒå¤šçš„ç±»åˆ«ä½¿ç”¨ under sampling (æ¬ é‡‡æ ·)ï¼Œä»¥å‡å°‘è¯¥ç±»åˆ«è®­ç»ƒæ•°æ®çš„æ•°é‡ï¼Œè€Œå¯¹æ•°é‡å°‘çš„ç±»åˆ«æ ·æœ¬ä½¿ç”¨ over sampling (è¿‡é‡‡æ ·)ï¼Œé€‚å½“é‡å¤ä¸€äº›æ ·æœ¬ï¼Œä»¥å¢åŠ è¯¥ç±»åˆ«çš„æ ·æœ¬æ•°é‡ã€‚

### Over-sampling / Under sampling processing order

åœ¨å½“å‰å®ç°æ–¹æ¡ˆä¸­ï¼Œå¯¹åŸå§‹æ—¥å¿—æ•°æ®å¤„ç†è¿‡åï¼Œå¦‚æœäº§ç”Ÿå¤šä¸ª ``npz`` æ–‡ä»¶ï¼Œè‹¥ä¸æ˜¯ä½¿ç”¨æ‰€æœ‰çš„æ•°æ®ç”¨äºè®­ç»ƒçš„è¯ï¼Œå½“å‰çš„ over-sampling / under sampling å¤„ç†çš„æ—¶é—´ç‚¹å¹¶ä¸åˆç†ï¼Œæˆ‘ä»¬çš„ç›®çš„æ˜¯å¯¹å°†è¦è¿›è¡Œè®­ç»ƒçš„æ•°æ®è¿›è¡Œç±»åˆ«çš„å¹³è¡¡ï¼Œæ‰€æœ‰è¿™ç§æƒ…å†µä¸‹ï¼Œåº”è¯¥æŠŠ over-sampling / under-sampling æ”¾åˆ°è®­ç»ƒæ¨¡å‹ä¹‹å‰ï¼Œè¯»å– ``npz`` æ•°æ®ä¹‹åã€‚